{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Class Weights.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPplfMLcucmiDLAvpIsOkbc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nickprock/corso_data_science/blob/master/imbalanced_classification/Class_Weights.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9bbhS41yinrV"
      },
      "source": [
        "# Imbalanced Classification\n",
        "## Class Weights\n",
        "\n",
        "Esempio con una regressione logistica su un dataset solo per far mostrare l'iperparametro da impostare e la learning curve come strumento di visualizzazione.\n",
        "\n",
        "*N.B. esperimento a scopo didattico, scusate se il processo non Ã¨ del tutto corretto*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VTvX02pFilGC"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xDQHgciKjEUf"
      },
      "source": [
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, learning_curve\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "reCqw7ptj11O"
      },
      "source": [
        "Creazione del dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XV9pd2_ljhfp"
      },
      "source": [
        "X, y = make_classification(n_samples=100000, n_features=4, weights=[0.99], flip_y=0.001, random_state=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eTho1x1Uk5Wc"
      },
      "source": [
        "np.bincount(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0FL9OhsJB-Ol"
      },
      "source": [
        "plt.figure(figsize=(18,10))\n",
        "plt.scatter(X[:,0], X[:,1], c=y, s = 100)\n",
        "plt.title(\"Imbalanced Dataset?\\n 99% - 1%\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wloUPJYUk8Cd"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, stratify=y, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYo1bks0nImQ"
      },
      "source": [
        "skf = StratifiedKFold(n_splits=5, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Itm-LNdIxUqQ"
      },
      "source": [
        "def learning_plot(train_sizes, train_scores, test_scores, title):\n",
        "  train_mean = np.mean(train_scores, axis = 1)\n",
        "  train_std = np.std(train_scores, axis = 1)\n",
        "  test_mean = np.mean(test_scores, axis = 1)\n",
        "  test_std = np.std(test_scores, axis = 1)\n",
        "\n",
        "  plt.plot(train_sizes, train_mean, color = 'blue', marker = 'o', markersize = 5, label = 'Training Recall')\n",
        "  plt.fill_between(train_sizes, train_mean + train_std, train_mean - train_std, alpha=0.15, color = 'blue')\n",
        "  plt.plot(train_sizes, test_mean, color = 'green', marker = '*', markersize = 5, label = 'Validation recall')\n",
        "  plt.fill_between(train_sizes, test_mean + test_std, test_mean - test_std, alpha=0.15, color = 'green')\n",
        "  plt.grid()\n",
        "  plt.xlabel('Number of Training Example')\n",
        "  plt.ylabel('Recall Score')\n",
        "  plt.legend()\n",
        "  plt.title(title)\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8h9a6FuoxEa"
      },
      "source": [
        "lr = LogisticRegression(class_weight=None, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FF2-aGzO_WZN"
      },
      "source": [
        "train_sizes_lr, train_scores_lr, val_scores_lr = learning_curve(lr, X_train, y_train, \n",
        "                                                        train_sizes=np.linspace(0.1,1.0,10), cv = skf, n_jobs = -1, scoring=\"recall\",\n",
        "                                                        verbose = 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6x4WLULE47VU"
      },
      "source": [
        "plt.figure(figsize = (10,8))\n",
        "learning_plot(train_sizes_lr, train_scores_lr, val_scores_lr, title=\"LR not weighted\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8GaXvOuE8hF"
      },
      "source": [
        "np.nanmean(train_scores_lr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXu125IYE8tb"
      },
      "source": [
        "np.nanmean(val_scores_lr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4dVwIDLIVgt"
      },
      "source": [
        "lr.fit(X_train, y_train)\n",
        "yhat_lr=lr.predict(X_test)\n",
        "\n",
        "print(\"accuracy: \", accuracy_score(y_test, yhat_lr))\n",
        "print(\"\\n\")\n",
        "print(\"precision: \", precision_score(y_test, yhat_lr))\n",
        "print(\"\\n\")\n",
        "print(\"recall: \", recall_score(y_test, yhat_lr))\n",
        "print(\"\\n\")\n",
        "print(\"F1: \", f1_score(y_test, yhat_lr))\n",
        "print(\"\\n\")\n",
        "print(\"\\n\")\n",
        "print(confusion_matrix(y_test, yhat_lr))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DP0htNeB5R4t"
      },
      "source": [
        "# oltre a \"balanced\" possono essere impostati i pesi delle classi inserendo una lista (vedere sulla documentazione)\n",
        "lr_w = LogisticRegression(class_weight=\"balanced\", random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GuhdiDoICaYm"
      },
      "source": [
        "train_sizes_lrw, train_scores_lrw, test_scores_lrw = learning_curve(lr_w, X_train, y_train, \n",
        "                                                        train_sizes=np.linspace(0.1,1.0,10), cv = skf, n_jobs = -1, scoring = 'recall',\n",
        "                                                        verbose = 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vpxlzu7sCdAd"
      },
      "source": [
        "plt.figure(figsize = (10,8))\n",
        "learning_plot(train_sizes_lrw, train_scores_lrw, test_scores_lrw, title=\"LR weighted\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GO3YqixtCfXH"
      },
      "source": [
        "np.nanmean(train_scores_lrw)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-fcFtlcEhib"
      },
      "source": [
        "np.nanmean(test_scores_lrw)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3Z4o8cEFVuD"
      },
      "source": [
        "lr_w.fit(X_train, y_train)\n",
        "yhat_lrw=lr_w.predict(X_test)\n",
        "\n",
        "print(\"accuracy: \", accuracy_score(y_test, yhat_lrw))\n",
        "print(\"\\n\")\n",
        "print(\"precision: \", precision_score(y_test, yhat_lrw))\n",
        "print(\"\\n\")\n",
        "print(\"recall: \", recall_score(y_test, yhat_lrw))\n",
        "print(\"\\n\")\n",
        "print(\"F1: \", f1_score(y_test, yhat_lrw))\n",
        "print(\"\\n\")\n",
        "print(\"\\n\")\n",
        "print(confusion_matrix(y_test, yhat_lrw))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-RArfbCKEz_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}