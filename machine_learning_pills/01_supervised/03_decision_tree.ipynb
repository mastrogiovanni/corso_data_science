{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "03_decision_tree.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOrUZ/Vqo4o29tkS6DG7uud",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nickprock/corso_data_science/blob/devs/machine_learning_pills/01_supervised/03_decision_tree.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZFgGQuUnZcp",
        "colab_type": "text"
      },
      "source": [
        "## Classificazione Multilabel\n",
        "\n",
        "### Decision tree\n",
        "\n",
        "In questo notebook vedremo quella che è forse la tecnica, se non più comune, più conosciuta per la classificazione, i **decision tree**.\n",
        "\n",
        "Questa tecnica è molto flessibile e potente, permette di catturare pattern ricorrenti da set di dati anche molto etogenei.\n",
        "\n",
        "<br>\n",
        "\n",
        "![dt](https://external-content.duckduckgo.com/iu/?u=http%3A%2F%2Fupload.wikimedia.org%2Fwikipedia%2Fcommons%2Ff%2Fff%2FDecision_tree_model.png&f=1&nofb=1)\n",
        "\n",
        "<br>\n",
        "\n",
        "[Image Credits](https://it.wikipedia.org/wiki/Albero_di_decisione)\n",
        "\n",
        "<br>\n",
        "\n",
        "Ogni nodo interno rappresenta una variabile, un arco verso un nodo figlio rappresenta un possibile valore per quella proprietà e una foglia il valore predetto per la variabile obiettivo a partire dai valori delle altre proprietà, che nell'albero è rappresentato dal cammino (path) dal nodo radice (root) al nodo foglia.\n",
        "\n",
        "### Dataset\n",
        "\n",
        "Il dataset utilizzato è il più famoso tra tutti e ogni corso di data scince ha almeno un esempio dove viene utilizzato: **Iris dataset**.\n",
        "\n",
        "Iris è un dataser di 150 osservazioni e 5 feturese:\n",
        "* sepal length\n",
        "* sepal width\n",
        "* petal length\n",
        "* petal width\n",
        "* species: variabile target\n",
        "\n",
        "La variabile target è categorica, può assumere tre valori:\n",
        "* setosa\n",
        "* virginica\n",
        "* versicolor\n",
        "\n",
        "Le tre classi sono perfettamente bilanciate, 50 osservazioni per classe. Le restanti 4 features sono numeriche continue.\n",
        "\n",
        "<br>\n",
        "\n",
        "![iris](https://external-content.duckduckgo.com/iu/?u=https%3A%2F%2Ftse1.mm.bing.net%2Fth%3Fid%3DOIP.STg6q7XX61Tox0fuGNwvRwHaFj%26pid%3DApi&f=1)\n",
        "\n",
        "<br>\n",
        "\n",
        "[Image Credits](https://www.panoramio.com/)\n",
        "\n",
        "<br>\n",
        "\n",
        "### Load Data\n",
        "\n",
        "Il dataset Iris è tra quelli disponibili in scikit-learn."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2WSAMOOunT4I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8izFpM0bt8NF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "iris = load_iris()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2XGMPY1xbFv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "iris"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kf3aJ9ASxe4A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "iris.data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qhtmTUVvxhJP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "iris.target"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2599yiVKxRcu",
        "colab_type": "text"
      },
      "source": [
        "Per semplicità utilizziamo solo due delle 4 fetures."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTLkmjPIuUlE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = iris.data[:, :2]\n",
        "y = iris.target"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pn_ITEEYzk13",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "colors = (\"red\", \"green\", \"blue\")\n",
        "groups = set(y)\n",
        "\n",
        "plt.scatter(x[:,0], x[:,1])\n",
        "plt.xlabel('petal length')\n",
        "plt.ylabel('petal width')\n",
        "plt.title('Iris')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UuxljDDoyd4g",
        "colab_type": "text"
      },
      "source": [
        "#### Visualizzare il decision tree\n",
        "\n",
        "Per mettere su un grafico l'albero generato abbiamo bisogno di una libreria apposita *export_graphviz*.\n",
        "\n",
        "Vediamo un breve esempio con un albero semplice."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ojCxvX1FycGt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tree_clf = DecisionTreeClassifier(max_depth=2) # solo due livelli (più nodo root)\n",
        "tree_clf.fit(x, y) # in questo caso alleniamo sull'intero dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uSs2cAukzdYe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.tree import export_graphviz\n",
        "\n",
        "export_graphviz(\n",
        "    tree_clf,\n",
        "    out_file = image_path(\"YOURPATH/image.dot\"),\n",
        "    feature_names = iris.feature_names[:2],\n",
        "    class_names = iris.class_names,\n",
        "    rounded = True,\n",
        "    filled = True\n",
        ")\n",
        "\n",
        "# successivamente bisogna convertire il .dot in un altro formato immagine"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yCuwYSaG3DFH",
        "colab_type": "text"
      },
      "source": [
        "![dt_iris](https://external-content.duckduckgo.com/iu/?u=https%3A%2F%2Fi.stack.imgur.com%2FJQpzN.png&f=1&nofb=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ls5bgf-R3Ior",
        "colab_type": "text"
      },
      "source": [
        "Si può notare che tutti i nodi hanno solo due foglie, questo succede perchè Scikit-learn usa l'algortimo CART che produce split binari. Altri algoritmi tipo ID3 invece possono produrre anche split con più di due nodi foglia.\n",
        "\n",
        "La scelta della variabile viene effettuata in base alla \"*purezza*\" del nodo.\n",
        "\n",
        "Per calcolare la purezza viene usato l'indice di Gini (non è l'unica metrica possibile), si dice che un nodo (variabile) è puro quando ha coefficiente zero, quindi tutte le osservazioni in ingresso in quel nodo verranno catalogate in una sola classe.\n",
        "\n",
        "Ad esempio in questo esercizio succede a Iris Setosa."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNDhhMHQ2QAD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_x, test_x, train_y, test_y = train_test_split(x, y, test_size = 0.3, random_state = 42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mVrgq1r-46Xd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tree_clf.fit(train_x, train_y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ha5V1LyC7L5_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "yhat = tree_clf.predict(test_x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1oZZhDcX7a6s",
        "colab_type": "text"
      },
      "source": [
        "### Valutazione del modello\n",
        "\n",
        "Abbiamo usato un modello senza impostare altri iperparametri se non la profondità dell'albero, valutiamo insieme il risultato."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_n7vcne7L3P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "print(\"confusion_matrix: \", \"\\n\",confusion_matrix(test_y, yhat))\n",
        "print(\"\\n\")\n",
        "print(\"accuracy: \", accuracy_score(test_y, yhat))\n",
        "print(\"\\n\")\n",
        "print(classification_report(test_y, yhat))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "myM9KlCP8_A6",
        "colab_type": "text"
      },
      "source": [
        "#### Tuning degli iperparametri\n",
        "\n",
        "Proviamo a fare tuning degli iperparametri del modello. Proveremo in particolare:\n",
        "* cambiare la metrica, da Gini a Entropy\n",
        "* rendere l'albero più profondo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M3vGy0UP8hxD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tree_clf_2 = DecisionTreeClassifier(criterion='entropy', max_depth = 5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zcKNgFv89idK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tree_clf_2.fit(train_x, train_y)\n",
        "yhat_2 = tree_clf_2.predict(test_x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ayK93Qm99ze2",
        "colab_type": "text"
      },
      "source": [
        "### Valutazione dei risultati"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QoLBVQAN94yO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"confusion_matrix: \", \"\\n\",confusion_matrix(test_y, yhat_2))\n",
        "print(\"\\n\")\n",
        "print(\"accuracy: \", accuracy_score(test_y, yhat_2))\n",
        "print(\"\\n\")\n",
        "print(classification_report(test_y, yhat_2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WIl-W1YL-I6T",
        "colab_type": "text"
      },
      "source": [
        "#### Tuning del modello\n",
        "\n",
        "Abbiamo fatto un diverso tuning del modello in maniera manuale.\n",
        "\n",
        "Scikit-learn ci fornisce alcuni strumenti per automatizzare questi passaggi. Il più semplice è la *Grid Search*.\n",
        "\n",
        "Essa non è altro che una serie di parametri che vengono impostati e il modello \"prova\" iterativamente. Il processo è dispendioso quindi vi consiglio di approfondire anche strimenti più avanzati.\n",
        "\n",
        "#### Cross-Validation\n",
        "\n",
        "<br>\n",
        "\n",
        "![CV](https://external-content.duckduckgo.com/iu/?u=https%3A%2F%2Fscikit-learn.org%2Fstable%2F_images%2Fgrid_search_cross_validation.png&f=1&nofb=1)\n",
        "\n",
        "<br>\n",
        "\n",
        "[Image Credits](https://scikit-learn.org/stable/modules/cross_validation.html)\n",
        "\n",
        "<br>\n",
        "\n",
        "La cross-validation è una tecnica che mira a costruire stimatori più robusti diminuendo l'errore dovuto al campionamento.\n",
        "\n",
        "Il modello non viene allenato su un unico set di dati di train ma lo stesso viene suddiviso in N parti (fold) e viene eseguito l'allenamento N volte su N-1 folds mentre l'ennesimo farà da validiation set.\n",
        "\n",
        "In questo modo ci si aspetta di avere un miglior tuning dei parametri, soprattutto per dataset di piccole dimensioni."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yum9ekB9_aXr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QKH7PQ59AKXZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tuned_params = [{'criterion':['gini','entropy'], 'max_depth':[2, 5, 10], 'min_samples_split':[2, 5, 10], 'splitter':['best', 'random']}]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRjvsPUqAKUq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "grid_tree_clf = GridSearchCV(estimator=DecisionTreeClassifier(), param_grid=tuned_params, n_jobs=-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5eUuZMf4Brv6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "grid_tree_clf.fit(train_x, train_y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3yWlThTPCBFF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "yhat_grid = grid_tree_clf.predict(test_x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ahR9OWGqCbwo",
        "colab_type": "text"
      },
      "source": [
        "### Valutazione dei risultati"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_YtkztDICbHm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"confusion_matrix: \", \"\\n\",confusion_matrix(test_y, yhat_grid))\n",
        "print(\"\\n\")\n",
        "print(\"accuracy: \", accuracy_score(test_y, yhat_grid))\n",
        "print(\"\\n\")\n",
        "print(classification_report(test_y, yhat_grid))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hyFqo60vFMXw",
        "colab_type": "text"
      },
      "source": [
        "### Esercizi\n",
        "\n",
        "1. Colorare lo scatterplot secondo l'etichetta del target\n",
        "2. Commentare i risultati\n",
        "3. Provare il modello con tutte e 4 le variabili indipendenti"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6da2TSQ4zxL",
        "colab_type": "text"
      },
      "source": [
        "### Link Utili\n",
        "\n",
        "[A Simple Explanation of Gini Impurity](https://victorzhou.com/blog/gini-impurity/)\n",
        "\n",
        "[Entropy](https://towardsdatascience.com/entropy-how-decision-trees-make-decisions-2946b9c18c8)\n",
        "\n",
        "[CART](https://machinelearningmastery.com/classification-and-regression-trees-for-machine-learning/)\n",
        "\n",
        "[ID3](https://medium.com/machine-learning-guy/an-introduction-to-decision-tree-learning-id3-algorithm-54c74eb2ad55)\n",
        "\n",
        "[Cross-Validation](https://scikit-learn.org/stable/modules/cross_validation.html)\n",
        "\n"
      ]
    }
  ]
}